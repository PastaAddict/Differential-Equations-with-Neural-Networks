{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gamer\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(0)\n",
    "LR = 3e-5\n",
    "MAX_EPOCH = 400\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDESolver(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PDESolver, self).__init__()\n",
    "        self.regressor = nn.Sequential(nn.Linear(2, 16),\n",
    "                                       nn.Tanh(),\n",
    "                                       nn.Linear(16, 32),\n",
    "                                       nn.Tanh(),\n",
    "                                       nn.Linear(32, 16),\n",
    "                                       nn.Tanh(),\n",
    "                                       nn.Linear(16, 1))\n",
    "    def forward(self, x):\n",
    "        output = self.regressor(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0,1,100)\n",
    "Y = np.linspace(0,1,100)\n",
    "X, Y = np.meshgrid(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.flatten()\n",
    "Y=Y.flatten()\n",
    "\n",
    "d=torch.Tensor([(X[i],Y[i]) for i in range(100**2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def f(d):\n",
    "#    return torch.tensor([torch.exp(-i[0])*(i[0]-2+i[1]**3+6*i[1]) for i in d])\n",
    "\n",
    "def f(d):\n",
    "    return torch.tensor([torch.exp(d[0] - d[1]) for i in d])\n",
    "\n",
    "F=torch.zeros(100**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train, D_val, F_train, F_val = train_test_split(d, F, test_size=0.2)\n",
    "train_dataloader = DataLoader(TensorDataset(D_train, F_train), batch_size=BATCH_SIZE,\n",
    "                              pin_memory=True, shuffle=True)\n",
    "val_dataloader = DataLoader(TensorDataset(D_val, F_val), batch_size=BATCH_SIZE,\n",
    "                            pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PDESolver().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 400\n",
      "tensor(2.7964, grad_fn=<MseLossBackward>)\n",
      "epoch 6 / 400\n",
      "tensor(1.5027, grad_fn=<MseLossBackward>)\n",
      "epoch 11 / 400\n",
      "tensor(1.1346, grad_fn=<MseLossBackward>)\n",
      "epoch 16 / 400\n",
      "tensor(0.2944, grad_fn=<MseLossBackward>)\n",
      "epoch 21 / 400\n",
      "tensor(0.2389, grad_fn=<MseLossBackward>)\n",
      "epoch 26 / 400\n",
      "tensor(0.1861, grad_fn=<MseLossBackward>)\n",
      "epoch 31 / 400\n",
      "tensor(0.1898, grad_fn=<MseLossBackward>)\n",
      "epoch 36 / 400\n",
      "tensor(0.2110, grad_fn=<MseLossBackward>)\n",
      "epoch 41 / 400\n",
      "tensor(0.1588, grad_fn=<MseLossBackward>)\n",
      "epoch 46 / 400\n",
      "tensor(0.1301, grad_fn=<MseLossBackward>)\n",
      "epoch 51 / 400\n",
      "tensor(0.0959, grad_fn=<MseLossBackward>)\n",
      "epoch 56 / 400\n",
      "tensor(0.0727, grad_fn=<MseLossBackward>)\n",
      "epoch 61 / 400\n",
      "tensor(0.0449, grad_fn=<MseLossBackward>)\n",
      "epoch 66 / 400\n",
      "tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "epoch 71 / 400\n",
      "tensor(0.0267, grad_fn=<MseLossBackward>)\n",
      "epoch 76 / 400\n",
      "tensor(0.0188, grad_fn=<MseLossBackward>)\n",
      "epoch 81 / 400\n",
      "tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "epoch 86 / 400\n",
      "tensor(0.0145, grad_fn=<MseLossBackward>)\n",
      "epoch 91 / 400\n",
      "tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "epoch 96 / 400\n",
      "tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "epoch 101 / 400\n",
      "tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "epoch 106 / 400\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "epoch 111 / 400\n",
      "tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "epoch 116 / 400\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "epoch 121 / 400\n",
      "tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "epoch 126 / 400\n",
      "tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "epoch 131 / 400\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "epoch 136 / 400\n",
      "tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "epoch 141 / 400\n",
      "tensor(0.0088, grad_fn=<MseLossBackward>)\n",
      "epoch 146 / 400\n",
      "tensor(0.0111, grad_fn=<MseLossBackward>)\n",
      "epoch 151 / 400\n",
      "tensor(0.0085, grad_fn=<MseLossBackward>)\n",
      "epoch 156 / 400\n",
      "tensor(0.0104, grad_fn=<MseLossBackward>)\n",
      "epoch 161 / 400\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "epoch 166 / 400\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "epoch 171 / 400\n",
      "tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "epoch 176 / 400\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "epoch 181 / 400\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "epoch 186 / 400\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "epoch 191 / 400\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "epoch 196 / 400\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "epoch 201 / 400\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "epoch 206 / 400\n",
      "tensor(0.0030, grad_fn=<MseLossBackward>)\n",
      "epoch 211 / 400\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "epoch 216 / 400\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "epoch 221 / 400\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "epoch 226 / 400\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "epoch 231 / 400\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "epoch 236 / 400\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "epoch 241 / 400\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "epoch 246 / 400\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "epoch 251 / 400\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "epoch 256 / 400\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 261 / 400\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "epoch 266 / 400\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 271 / 400\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "epoch 276 / 400\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 281 / 400\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "epoch 286 / 400\n",
      "tensor(8.2520e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 291 / 400\n",
      "tensor(6.7506e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 296 / 400\n",
      "tensor(5.0854e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 301 / 400\n",
      "tensor(2.9676e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 306 / 400\n",
      "tensor(1.9988e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 311 / 400\n",
      "tensor(3.4719e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 316 / 400\n",
      "tensor(3.9129e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 321 / 400\n",
      "tensor(2.9150e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 326 / 400\n",
      "tensor(1.9843e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 331 / 400\n",
      "tensor(1.2864e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 336 / 400\n",
      "tensor(1.1545e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 341 / 400\n",
      "tensor(1.5225e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 346 / 400\n",
      "tensor(8.3138e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 351 / 400\n",
      "tensor(1.4196e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 356 / 400\n",
      "tensor(1.3013e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 361 / 400\n",
      "tensor(9.4708e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 366 / 400\n",
      "tensor(1.5859e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 371 / 400\n",
      "tensor(5.7537e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 376 / 400\n",
      "tensor(1.0661e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 381 / 400\n",
      "tensor(5.8080e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 386 / 400\n",
      "tensor(6.6460e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 391 / 400\n",
      "tensor(8.2891e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 396 / 400\n",
      "tensor(4.6906e-06, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    j=0\n",
    "    model.train()\n",
    "    # training loop\n",
    "    temp_loss_list = list()\n",
    "    for d, F in train_dataloader:\n",
    "        d = d.type(torch.float32).to(device)\n",
    "        d.requires_grad = True\n",
    "        \n",
    "        x=d[:,0]\n",
    "        y=d[:,1]\n",
    "        F = F.type(torch.float32).to(device)\n",
    "        \n",
    "        ## nn output (u) and derivatives\n",
    "        u = model(d) \n",
    "        du = sum([torch.autograd.grad(outputs=out, inputs=d, create_graph=True)[0] for i, out in enumerate(u)])\n",
    "        udx=du[:,0]\n",
    "        udy=du[:,1]\n",
    "        #ddudx = sum([torch.autograd.grad(outputs=out, inputs=d, retain_graph=True)[0] for i, out in enumerate(udx)])\n",
    "        #ddudy = sum([torch.autograd.grad(outputs=out, inputs=d, retain_graph=True)[0] for i, out in enumerate(udy)])\n",
    "        #udxdx=ddudx[:,0]\n",
    "        #udydy=ddudy[:,1]\n",
    "        \n",
    "        \n",
    "        ####\n",
    "        u=torch.reshape(u, (-1,))\n",
    "        #Axx=(y-1)*torch.exp(-x)*(2-x)+y*torch.exp(-x)*(x-1)\n",
    "        #Ayy=6*y*(1-x)+6*y*x*np.exp(-1.0)\n",
    "        #uxx=Axx -2*y*(1-y)*u+(1-2*x)*y*(1-y)*udx+(1-x)*y*(1-y)*udx-x*y*(1-y)*udx+x*(1-x)*y*(1-y)*udxdx                    \n",
    "        #uyy=Ayy -2*x*(1-x)*u+(1-2*y)*x*(1-x)*udy+(1-y)*x*(1-x)*udy-y*x*(1-x)*udy+y*(1-y)*x*(1-x)*udydy                    \n",
    "        ux = torch.exp(x) + y*udx\n",
    "        uy = u + y*udy\n",
    "        \n",
    "    \n",
    "    \n",
    "        loss = criterion(input=ux+uy, target=F)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        temp_loss_list.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    temp_loss_list = list()\n",
    "    \n",
    "    if epoch%5==0:\n",
    "        print(\"epoch %d / %d\" % (epoch+1, MAX_EPOCH))\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Line3DCollection at 0x21b96dfca90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.linspace(0,1,100)\n",
    "Y = np.linspace(0,1,100)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z=np.exp(X-Y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "#ax.plot_wireframe(X, Y, Z)\n",
    "\n",
    "x=X.flatten()\n",
    "y=Y.flatten()\n",
    "\n",
    "d=torch.Tensor([(x[i],y[i]) for i in range(100**2)])\n",
    "\n",
    "\n",
    "u=model(d).detach().numpy()\n",
    "U=u.reshape(-1)*y+np.exp(x)\n",
    "\n",
    "ax.plot_wireframe(X, Y, np.abs(U.reshape(100,100)-Z), color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.0101522 , 1.02040746, ..., 2.66391802, 2.69096264,\n",
       "        2.71828183],\n",
       "       [0.98994983, 1.        , 1.0101522 , ..., 2.6371452 , 2.66391802,\n",
       "        2.69096264],\n",
       "       [0.98000067, 0.98994983, 1.        , ..., 2.61064146, 2.6371452 ,\n",
       "        2.66391802],\n",
       "       ...,\n",
       "       [0.37538693, 0.37919793, 0.38304762, ..., 1.        , 1.0101522 ,\n",
       "        1.02040746],\n",
       "       [0.37161423, 0.37538693, 0.37919793, ..., 0.98994983, 1.        ,\n",
       "        1.0101522 ],\n",
       "       [0.36787944, 0.37161423, 0.37538693, ..., 0.98000067, 0.98994983,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.41273368e-05, 1.90273883e-05, 1.42907725e-05, ...,\n",
       "        8.78893317e-05, 1.17020696e-04, 1.49238983e-04],\n",
       "       [5.26467021e-05, 4.21378337e-05, 3.23500368e-05, ...,\n",
       "        1.53391139e-04, 2.08512798e-04, 2.69640888e-04],\n",
       "       ...,\n",
       "       [6.73136452e-02, 6.57959421e-02, 6.42901141e-02, ...,\n",
       "        6.07008037e-04, 6.41073858e-04, 6.82412673e-04],\n",
       "       [6.88899963e-02, 6.73561851e-02, 6.58337424e-02, ...,\n",
       "        6.57210299e-04, 6.89840954e-04, 7.30503493e-04],\n",
       "       [7.04814287e-02, 6.89314886e-02, 6.73931148e-02, ...,\n",
       "        7.14605405e-04, 7.45733954e-04, 7.85194929e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(U.reshape(100,100)-Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
